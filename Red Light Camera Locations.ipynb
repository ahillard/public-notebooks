{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the URLs for the JSON data powering the ESRI/ArcGIS maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "few_crashes_url = 'http://www.arcgis.com/sharing/rest/content/items/5a8841f92e4a42999c73e9a07aca0c23/data?f=json&token=lddNjwpwjOibZcyrhJiogNmyjIZmzh-pulx7jPD9c559e05tWo6Qr8eTcP7Deqw_CIDPwZasbNOCSBHfthynf-8WRMmguxHbIFptbZQvnpRupJHSY8Abrz__xUteBS93MitgvoU6AqSN5eDVKRYiUg..'\n",
    "removed_url = 'http://www.arcgis.com/sharing/rest/content/items/1e01ac5dc4d54dc186502316feab156e/data?f=json&token=lddNjwpwjOibZcyrhJiogNmyjIZmzh-pulx7jPD9c559e05tWo6Qr8eTcP7Deqw_CIDPwZasbNOCSBHfthynf-8WRMmguxHbIFptbZQvnpRupJHSY8Abrz__xUteBS93MitgvoU6AqSN5eDVKRYiUg..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to easily extract the actual data points from the JSON. The data will actually contain multiple layers (really, one layer per `operationalLayer`, but multiple `operationalLayers`) so, if we pass a title, we should return the `operationalLayer` corresponding to that title; otherwise, just return the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 193 data points for few-crash intersections, 195 total cameras and 25 removed camera locations\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "def extract_features(url, title=None):\n",
    "    r = requests.get(url)\n",
    "    idx = 0\n",
    "    found = False\n",
    "    if title:\n",
    "        while idx < len(r.json()['operationalLayers']):\n",
    "            for item in r.json()['operationalLayers'][idx].items():\n",
    "                if item[0] == 'title' and item[1] == title:\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "            idx += 1\n",
    "    try:\n",
    "        return r.json()['operationalLayers'][idx]['featureCollection']['layers'][0]['featureSet']['features']\n",
    "    except IndexError, e:\n",
    "        return {}\n",
    "\n",
    "few_crashes = extract_features(few_crashes_url)\n",
    "all_cameras = extract_features(removed_url, 'All Chicago red light cameras')\n",
    "removed_cameras = extract_features(removed_url, 'red-light-cams')\n",
    "print 'Found %d data points for few-crash intersections, %d total cameras and %d removed camera locations' % (\n",
    "    len(few_crashes), len(all_cameras), len(removed_cameras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to filter out the bad points from few_crashes - the ones with 0 given as the lat/lon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_few_crashes = [\n",
    "    point for point in few_crashes if point['attributes']['LONG_X'] != 0 and point['attributes']['LAT_Y'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a dictionary of all the cameras, so we can merge all their info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cameras = {}\n",
    "for point in all_cameras:\n",
    "    label = point['attributes']['LABEL']\n",
    "    if label not in cameras:\n",
    "        cameras[label] = point\n",
    "        cameras[label]['attributes']['Few crashes'] = False\n",
    "        cameras[label]['attributes']['To be removed'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `'Few crashes'` flag to True for those intersections that show up in `filtered_few_crashes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for point in filtered_few_crashes:\n",
    "    label = point['attributes']['LABEL']\n",
    "    if label not in cameras:\n",
    "        print 'Missing label %s' % label\n",
    "    else:\n",
    "        cameras[label]['attributes']['Few crashes'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `'To be removed'` flag to True for those intersections that show up in `removed_cameras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for point in removed_cameras:\n",
    "    label = point['attributes']['displaylabel'].replace(' and ', '-')\n",
    "    if label not in cameras:\n",
    "        print 'Missing label %s' % label\n",
    "    else:\n",
    "        cameras[label]['attributes']['To be removed'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many camera locations have few crashes and were slated to be removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 locations had few crashes and were slated to be removed: Kimball-Lincoln-McCormick; Osceola-Touhy; Vincennes-111th; Western-Pratt; Pulaski-Montrose; Cicero-Stevenson NB; Cottage Grove-95th; Harlem-Northwest Highway; Cornell-57th; Ashland-Diversey; Halsted-63rd; Elston-LaPorte-Foster\n",
      "\n",
      "61 locations had few crashes but were not slated to be removed: California-Devon; Central-Lake; Western-Van Buren; Broadway-Sheridan-Devon; Laramie-Madison; Pulaski-Lawrence; Canal-Roosevelt; Cicero-Diversey; Kedzie-47th; Halsted-North; Stony Island-89th; Western-Madison; Illinois-Columbus; Kedzie-Irving Park; Pulaski-Division; Central-Irving Park; Pulaski-Armitage; Kedzie-Armitage; Cicero-Armitage; Clark-Irving Park; Oak Park-Grand; Sacramento-Lake; Western-Chicago; Western-Cermak; Ashland-Lawrence; Damen-63rd; Wells-North; California-47th; Central-Chicago; Ontario-Kingsbury; Cicero-Harrison; Central-Diversey; Kilpatrick-Irving Park; Western-Addison; Western-71st; Pulaski-Diversey; Pulaski-North; Central-Addison; Clark-Fullerton; Clark-Chicago; Western-Touhy; Halsted-Roosevelt; California-Irving Park; Broadway-Foster; Pulaski-71ST; Western-Montrose; Halsted-Madison; Austin-Diversey; Kedzie-Devon; Kedzie-26th; Kostner-Division; Elston-Lawrence; Harlem-Addison; Lake Shore-Belmont; Racine-79th; Cicero-Peterson; Milwaukee-Montrose; Elston-Irving Park; Kedzie-55th; Elston-Addison; Damen-Division\n",
      "\n",
      "13 locations were slated to be removed despite having reasonable numbers of crashes: Damen-Blue Island; Narragansett-55th-Archer; Stony Island-83rd; Western-51st; Ashland-Archer; Ashland-47th; Central-Madison; Ashland-63rd; Halsted-83rd; California-31st; Jeffery-79th; Ashland-Garfield; Western-Armitage\n"
     ]
    }
   ],
   "source": [
    "counter = {\n",
    "    'both': {\n",
    "        'names': [],\n",
    "        'count': 0\n",
    "    },\n",
    "    'crashes only': {\n",
    "        'names': [],\n",
    "        'count': 0\n",
    "    },\n",
    "    'removed only': {\n",
    "        'names': [],\n",
    "        'count': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "for camera in cameras:\n",
    "    if cameras[camera]['attributes']['Few crashes']:\n",
    "        if cameras[camera]['attributes']['To be removed']:\n",
    "            counter['both']['count'] += 1\n",
    "            counter['both']['names'].append(camera)\n",
    "        else:\n",
    "            counter['crashes only']['count'] += 1\n",
    "            counter['crashes only']['names'].append(camera)\n",
    "    elif cameras[camera]['attributes']['To be removed']:\n",
    "        counter['removed only']['count'] += 1\n",
    "        counter['removed only']['names'].append(camera)\n",
    "\n",
    "print '%d locations had few crashes and were slated to be removed: %s\\n' % (\n",
    "    counter['both']['count'], '; '.join(counter['both']['names']))\n",
    "print '%d locations had few crashes but were not slated to be removed: %s\\n' % (\n",
    "    counter['crashes only']['count'], '; '.join(counter['crashes only']['names']))\n",
    "print '%d locations were slated to be removed despite having reasonable numbers of crashes: %s' % (\n",
    "    counter['removed only']['count'], '; '.join(counter['removed only']['names']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this list compare to the one currently published on the Chicago Data Portal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "from StringIO import StringIO\n",
    "\n",
    "data_portal_url = 'https://data.cityofchicago.org/api/views/thvf-6diy/rows.csv?accessType=DOWNLOAD'\n",
    "r = requests.get(data_portal_url)\n",
    "fh = StringIO(r.text)\n",
    "reader = DictReader(fh)\n",
    "\n",
    "def cleaner(str):\n",
    "    filters = [\n",
    "        ('Stony?Island', 'Stony Island'),\n",
    "        ('Van?Buren', 'Van Buren'),\n",
    "        (' (SOUTH INTERSECTION)', '')\n",
    "    ]\n",
    "    for filter in filters:\n",
    "        str = str.replace(filter[0], filter[1])\n",
    "    return str\n",
    "\n",
    "for line in reader:\n",
    "    line['INTERSECTION'] = cleaner(line['INTERSECTION'])\n",
    "    cameras[line['INTERSECTION']]['attributes']['current'] = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current 151\n",
      "Pulaski-63rd; Sheridan-Hollywood; California-Devon; Pulaski-Belmont; Central-Lake; Austin-Irving Park; Harlem-Belmont; Western-Van Buren; Broadway-Sheridan-Devon; State-63rd; Sheridan-Foster; Laramie-Madison; Pulaski-Lawrence; Canal-Roosevelt; Western-Foster; Cicero-Diversey; State-75th; Kedzie-47th; Jeffery-95th; Pulaski-Foster; Narragansett-Irving Park; Halsted-North; Western-Marquette; Cicero-North; Damen-Diversey-Clybourn; Western-Fullerton; Halsted-Division; Stony Island-79th-South Chicago; California-Diversey; Western-Madison; State-79th; Illinois-Columbus; Kedzie-Irving Park; Pulaski-Division; Central-Irving Park; Osceola-Touhy; Pulaski-Armitage; California-Peterson; Western-63rd; Halsted-79th; Western-55th; Kedzie-Armitage; Cicero-Armitage; Clark-Irving Park; Pulaski-Peterson; Halsted-Fullerton-Lincoln; Central-Belmont; Western-Lawrence; Ashland-87th; Milwaukee-Diversey; Oak Park-Grand; Pulaski-Chicago; Sacramento-Lake; Western-Chicago; Vincennes-87th; Pulaski-79th; Ashland-95th; Kostner-Roosevelt; Western-Cermak; Pulaski-55th; Laramie-Fullerton; Ashland-Lawrence; Kostner-Grand-North; LaSalle-Kinzie; Laramie-Irving Park; Damen-63rd; Clark-Ridge; Halsted-119th; Stony Island-Cornell-67th; Nagle-Foster; Cicero-Fullerton; Cicero-47th; Central-Chicago; Cicero-Archer; Pulaski-Cermak; Cicero-Stevenson NB; Cicero-Harrison; Ashland-71st; Central-Diversey; Sacramento-Chicago; Halsted-111th; Cicero-Washington; Kilpatrick-Irving Park; Western-Devon; Western-79th; Halsted-99th; Narragansett-Fullerton; Kedzie-31st; Western-Addison; Stony Island-76th; Lafayette-87th; Pulaski-Irving Park; Western-71st; Pulaski-Diversey; Pulaski-North; Central-Addison; Clark-Fullerton; Clark-Chicago; Hamlin-Madison; Austin-Addison; Stony Island-95th; Ashland-Madison; Ashland-Irving Park; Western-Touhy; Halsted-Roosevelt; Halsted-95th; Western-Peterson; Pulaski-Roosevelt; California-Irving Park; Broadway-Foster; Damen-Fullerton-Elston; Ashland-Division; Pulaski-Fullerton; Kedzie-Belmont; Western-Montrose; Cicero-Addison; Western-Pershing; Milwaukee-Devon; Halsted-Madison; Western-47th; Ashland-Fullerton; Kedzie-79th-Columbus; Austin-Diversey; Western-Diversey-Elston; Kedzie-26th; Western-North; Elston-Lawrence; Kostner-Ogden; Harlem-Addison; Lake Shore-Belmont; Homan-Kimball-North; Pulaski-Archer-50th; Halsted-103rd; Ashland-Cortland; Cicero-Chicago; Cicero-Peterson; Milwaukee-Montrose; Cicero-Lawrence; Dr Martin Luther King-31st; Elston-Irving Park; Cottage Grove-71st-South Chicago; Western-35th; Halsted-115th; Kedzie-71st; Kedzie-55th; Wentworth-Garfield; Central-Fullerton; Kedzie-63rd; Elston-Addison; Damen-Division; Hamlin-Lake \n",
      "\n",
      "not current and not slated for removal 21\n",
      "Stony Island-89th; Clark-Cermak; Roosevelt-Ashland; Wentworth-69th; Halsted-Belmont; Roosevelt-State; Wells-North; California-47th; California-35th; Irving Park-Western; Ontario-Kingsbury; Fullerton-Kedzie; Harlem-Higgins; Austin-Belmont; California-North; Cicero-Belmont; Pulaski-71ST; Cottage Grove-79th; Kedzie-Devon; Kostner-Division; Racine-79th \n",
      "\n",
      "not current and slated for removal 23\n",
      "Kimball-Lincoln-McCormick; Damen-Blue Island; Narragansett-55th-Archer; Vincennes-111th; Western-Pratt; Stony Island-83rd; Western-51st; Ashland-Archer; Pulaski-Montrose; Ashland-47th; Cottage Grove-95th; Central-Madison; Ashland-63rd; Halsted-83rd; Harlem-Northwest Highway; California-31st; Jeffery-79th; Cornell-57th; Ashland-Diversey; Ashland-Garfield; Halsted-63rd; Western-Armitage; Elston-LaPorte-Foster \n",
      "\n",
      "current and slated for removal 2\n",
      "Osceola-Touhy; Cicero-Stevenson NB \n",
      "\n",
      "not current 44\n",
      "Kimball-Lincoln-McCormick; Damen-Blue Island; Narragansett-55th-Archer; Stony Island-89th; Clark-Cermak; Vincennes-111th; Western-Pratt; Roosevelt-Ashland; Stony Island-83rd; Western-51st; Wentworth-69th; Halsted-Belmont; Ashland-Archer; Roosevelt-State; Wells-North; Pulaski-Montrose; California-47th; California-35th; Irving Park-Western; Ontario-Kingsbury; Ashland-47th; Cottage Grove-95th; Fullerton-Kedzie; Harlem-Higgins; Central-Madison; Austin-Belmont; Ashland-63rd; Halsted-83rd; California-North; Harlem-Northwest Highway; Cicero-Belmont; California-31st; Jeffery-79th; Pulaski-71ST; Cottage Grove-79th; Kedzie-Devon; Kostner-Division; Cornell-57th; Ashland-Diversey; Racine-79th; Ashland-Garfield; Halsted-63rd; Western-Armitage; Elston-LaPorte-Foster \n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = {\n",
    "    'not current': [],\n",
    "    'current': [],\n",
    "    'not current and slated for removal': [],\n",
    "    'not current and not slated for removal': [],\n",
    "    'current and slated for removal': []\n",
    "}\n",
    "for camera in cameras:\n",
    "    if 'current' not in cameras[camera]['attributes']:\n",
    "        counter['not current'].append(camera)\n",
    "        if cameras[camera]['attributes']['To be removed']:\n",
    "            counter['not current and slated for removal'].append(camera)\n",
    "        else:\n",
    "            counter['not current and not slated for removal'].append(camera)\n",
    "    else:\n",
    "        counter['current'].append(camera)\n",
    "        if cameras[camera]['attributes']['To be removed']:\n",
    "            counter['current and slated for removal'].append(camera)\n",
    "\n",
    "for key in counter:\n",
    "    print key, len(counter[key])\n",
    "    print '; '.join(counter[key]), '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compute how much money has been generated at each intersection - assuming $100 fine for each violation. In order to do that, we need to make the violation data line up with the camera location data.\n",
    "\n",
    "Then, we'll add 3 fields: number of violations overall; number on/after 12/22/2014; number on/after 3/6/2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 0 intersections set([])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from csv import DictReader\n",
    "from datetime import datetime\n",
    "from StringIO import StringIO\n",
    "\n",
    "data_portal_url = 'https://data.cityofchicago.org/api/views/spqx-js37/rows.csv?accessType=DOWNLOAD'\n",
    "r = requests.get(data_portal_url)\n",
    "fh = StringIO(r.text)\n",
    "reader = DictReader(fh)\n",
    "\n",
    "def violation_cleaner(str):\n",
    "    filters = [\n",
    "        (' AND ', '-'),\n",
    "        (' and ', '-'),\n",
    "        ('/', '-'),\n",
    "        # These are streets spelled one way in ticket data, another way in location data\n",
    "        ('STONEY ISLAND', 'STONY ISLAND'),\n",
    "        ('CORNELL DRIVE', 'CORNELL'),\n",
    "        ('NORTHWEST HWY', 'NORTHWEST HIGHWAY'),\n",
    "        ('CICERO-I55', 'CICERO-STEVENSON NB'),\n",
    "        ('31ST ST-MARTIN LUTHER KING DRIVE', 'DR MARTIN LUTHER KING-31ST'),\n",
    "        ('4700 WESTERN', 'WESTERN-47TH'),\n",
    "        ('LAKE SHORE DR-BELMONT', 'LAKE SHORE-BELMONT'),\n",
    "        # These are 3-street intersections where the ticket data has 2 streets, location data has 2 other streets\n",
    "        ('KIMBALL-DIVERSEY', 'MILWAUKEE-DIVERSEY'),\n",
    "        ('PULASKI-ARCHER', 'PULASKI-ARCHER-50TH'),\n",
    "        ('KOSTNER-NORTH', 'KOSTNER-GRAND-NORTH'),\n",
    "        ('79TH-KEDZIE', 'KEDZIE-79TH-COLUMBUS'),\n",
    "        ('LINCOLN-MCCORMICK', 'KIMBALL-LINCOLN-MCCORMICK'),\n",
    "        ('KIMBALL-LINCOLN', 'KIMBALL-LINCOLN-MCCORMICK'),\n",
    "        ('DIVERSEY-WESTERN', 'WESTERN-DIVERSEY-ELSTON'),\n",
    "        ('HALSTED-FULLERTON', 'HALSTED-FULLERTON-LINCOLN'),\n",
    "        ('COTTAGE GROVE-71ST', 'COTTAGE GROVE-71ST-SOUTH CHICAGO'),\n",
    "        ('DAMEN-FULLERTON', 'DAMEN-FULLERTON-ELSTON'),\n",
    "        ('DAMEN-DIVERSEY', 'DAMEN-DIVERSEY-CLYBOURN'),\n",
    "        ('ELSTON-FOSTER', 'ELSTON-LAPORTE-FOSTER'),\n",
    "        ('STONY ISLAND-79TH', 'STONY ISLAND-79TH-SOUTH CHICAGO'),\n",
    "        # This last one is an artifact of the filter application process\n",
    "        ('KIMBALL-LINCOLN-MCCORMICK-MCCORMICK', 'KIMBALL-LINCOLN-MCCORMICK')\n",
    "    ]\n",
    "    for filter in filters:\n",
    "        str = str.replace(filter[0], filter[1])\n",
    "    return str\n",
    "\n",
    "def intersection_is_reversed(key, intersection):\n",
    "    split_key = key.upper().split('-')\n",
    "    split_intersection = intersection.upper().split('-')\n",
    "    if len(split_key) != len(split_intersection):\n",
    "        return False\n",
    "    for k in split_key:\n",
    "        if k not in split_intersection:\n",
    "            return False\n",
    "    for k in split_intersection:\n",
    "        if k not in split_key:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "missing_intersections = set()\n",
    "for idx, line in enumerate(reader):\n",
    "    line['INTERSECTION'] = violation_cleaner(line['INTERSECTION'])\n",
    "    found = False\n",
    "    for key in cameras:\n",
    "        if key.lower() == line['INTERSECTION'].lower() or intersection_is_reversed(key, line['INTERSECTION']):\n",
    "            found = True\n",
    "            if 'total tickets' not in cameras[key]['attributes']:\n",
    "                cameras[key]['attributes']['total tickets'] = 0\n",
    "                cameras[key]['attributes']['tickets since 12/22/2014'] = 0\n",
    "                cameras[key]['attributes']['tickets since 3/6/2015'] = 0\n",
    "                cameras[key]['attributes']['last ticket date'] = line['VIOLATION DATE']\n",
    "            else:\n",
    "                cameras[key]['attributes']['total tickets'] += int(line['VIOLATIONS'])\n",
    "                dt = datetime.strptime(line['VIOLATION DATE'], '%m/%d/%Y')\n",
    "                if dt >= datetime.strptime('12/22/2014', '%m/%d/%Y'):\n",
    "                    cameras[key]['attributes']['tickets since 12/22/2014'] += int(line['VIOLATIONS'])\n",
    "                if dt >= datetime.strptime('3/6/2015', '%m/%d/%Y'):\n",
    "                    cameras[key]['attributes']['tickets since 3/6/2015'] += int(line['VIOLATIONS'])\n",
    "    if not found:\n",
    "        missing_intersections.add(line['INTERSECTION'])\n",
    "print 'Missing %d intersections' % len(missing_intersections), missing_intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now it's time to ask some specific questions. First: how much money has the program raised overall? (Note that this data only goes back to 7/1/2014, several years after the program began.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768887 tickets have been issued since 7/1/2014, raising $76,888,700.00\n",
      "The following 21 intersections appear to never have issued a ticket in that time: Stony Island-89th; Clark-Cermak; Roosevelt-Ashland; Wentworth-69th; Halsted-Belmont; Roosevelt-State; Wells-North; California-47th; California-35th; Irving Park-Western; Ontario-Kingsbury; Fullerton-Kedzie; Harlem-Higgins; Austin-Belmont; California-North; Cicero-Belmont; Pulaski-71ST; Cottage Grove-79th; Kedzie-Devon; Kostner-Division; Racine-79th\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale( locale.LC_ALL, '' )\n",
    "\n",
    "total = 0\n",
    "missing_tickets = []\n",
    "for camera in cameras:\n",
    "    try:\n",
    "        total += cameras[camera]['attributes']['total tickets']\n",
    "    except KeyError:\n",
    "        missing_tickets.append(camera)\n",
    "\n",
    "print '%d tickets have been issued since 7/1/2014, raising %s' % (total, locale.currency(total * 100, grouping=True))\n",
    "print 'The following %d intersections appear to never have issued a ticket in that time: %s' % (\n",
    "    len(missing_tickets), '; '.join(missing_tickets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 12/22/2014, how much money has been generated by low-crash intersections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178141 tickets have been issued at low-crash intersections since 12/22/2014, raising $17,814,100.00\n",
      "513980 tickets have been issued overall since 12/22/2014, raising $51,398,000.00\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "low_crash_total = 0\n",
    "for camera in cameras:\n",
    "    try:\n",
    "        total += cameras[camera]['attributes']['tickets since 12/22/2014']\n",
    "        if cameras[camera]['attributes']['Few crashes']:\n",
    "            low_crash_total += cameras[camera]['attributes']['tickets since 12/22/2014']\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "print '%d tickets have been issued at low-crash intersections since 12/22/2014, raising %s' % (\n",
    "    low_crash_total, locale.currency(low_crash_total * 100, grouping=True))\n",
    "print '%d tickets have been issued overall since 12/22/2014, raising %s' % (\n",
    "    total, locale.currency(total * 100, grouping=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about since 3/6/2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145503 tickets have been issued at low-crash intersections since 3/6/2015, raising $14,550,300.00\n",
      "429153 tickets have been issued overall since 3/6/2015, raising $42,915,300.00\n",
      "3213 tickets have been issued at cameras that were supposed to be closed since 3/6/2015, raising $321,300.00\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "low_crash_total = 0\n",
    "slated_for_closure_total = 0\n",
    "for camera in cameras:\n",
    "    try:\n",
    "        total += cameras[camera]['attributes']['tickets since 3/6/2015']\n",
    "        if cameras[camera]['attributes']['Few crashes']:\n",
    "            low_crash_total += cameras[camera]['attributes']['tickets since 3/6/2015']\n",
    "        if cameras[camera]['attributes']['To be removed']:\n",
    "            slated_for_closure_total += cameras[camera]['attributes']['tickets since 3/6/2015']\n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "print '%d tickets have been issued at low-crash intersections since 3/6/2015, raising %s' % (\n",
    "    low_crash_total, locale.currency(low_crash_total * 100, grouping=True))\n",
    "print '%d tickets have been issued overall since 3/6/2015, raising %s' % (\n",
    "    total, locale.currency(total * 100, grouping=True))\n",
    "print '%d tickets have been issued at cameras that were supposed to be closed since 3/6/2015, raising %s' % (\n",
    "    slated_for_closure_total, locale.currency(slated_for_closure_total * 100, grouping=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a CSV of the cameras data for export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from csv import DictWriter\n",
    "output = []\n",
    "\n",
    "for camera in cameras:\n",
    "    data = {\n",
    "        'intersection': camera,\n",
    "        'last ticket date': cameras[camera]['attributes'].get('last ticket date', ''),\n",
    "        'tickets since 7/1/2014': cameras[camera]['attributes'].get('total tickets', 0),\n",
    "        'revenue since 7/1/2014': cameras[camera]['attributes'].get('total tickets', 0) * 100,\n",
    "        'tickets since 12/22/2014': cameras[camera]['attributes'].get('tickets since 12/22/2014', 0),\n",
    "        'revenue since 12/22/2014': cameras[camera]['attributes'].get('tickets since 12/22/2014', 0) * 100,\n",
    "        'was slated for removal': cameras[camera]['attributes'].get('To be removed', False),\n",
    "        'had few crashes': cameras[camera]['attributes'].get('Few crashes', False),\n",
    "        'is currently active': True if 'current' in cameras[camera]['attributes'] else False,\n",
    "        'latitude': cameras[camera]['attributes'].get('LAT', 0),\n",
    "        'longitude': cameras[camera]['attributes'].get('LNG', 0)\n",
    "    }\n",
    "    output.append(data)\n",
    "\n",
    "with open('/tmp/red_light_intersections.csv', 'w+') as fh:\n",
    "    writer = DictWriter(fh, sorted(output[0].keys()))\n",
    "    writer.writeheader()\n",
    "    writer.writerows(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
